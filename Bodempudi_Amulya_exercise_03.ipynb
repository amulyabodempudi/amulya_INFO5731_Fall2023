{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amulyabodempudi/amulya_INFO5731_Fall2023/blob/main/Bodempudi_Amulya_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "## The third In-class-exercise (due on 11:59 PM 10/08/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2htC-oV70ne"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b49221c4-2e27-4f6d-ac91-8e4d908af0a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nAn interesting text classification task could be Spam Detection to Identify whether an email or message is spam or not.\\nThis involves classifying incoming messages into \"spam\" or \"not spam\" categories.\\n\\nBelow are the features that are useful for building a machine learning model:\\n\\nBag of Words (BoW) Features:\\nWord Frequency: Count the frequency of each word in the review. Positive sentiment may be associated with words like \"delicious,\" \"amazing,\" \\nand \"friendly,\" while negative sentiment may be linked to words like \"disappointing,\" \"awful,\" and \"rude.\"\\n\\nN-grams Features:\\nBi-grams and Tri-grams: Consider word pairs (bi-grams) and word triplets (tri-grams) in addition to individual words. This can capture phrases \\nlike \"horrible service\" or \"good food\" which carry sentiment information.\\n\\nTemporal Features:\\nReview Date and Time: Consider the timestamp of the review, as sentiment may vary over time. Reviews written shortly after a dining experience \\nmight be more emotionally charged than those written later.\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency) Features:\\nTF-IDF Scores: Calculate TF-IDF scores for each word in the review. This helps in giving more weight to words that are important to a \\nspecific review while downplaying common words.\\n\\nPunctuation and Capitalization Features:\\nPunctuation Usage: Count the number of exclamation points, question marks, or ellipses in the review. Excessive use of exclamation points might \\nindicate enthusiasm in positive reviews or frustration in negative reviews.\\n\\nPart-of-Speech (POS) Features:\\nPOS Tag Frequencies: Count the frequency of different parts of speech in the review, such as nouns, adjectives, verbs, and adverbs. Positive reviews\\nmight have a higher frequency of positive adjectives and verbs, while negative reviews might have more negative adjectives and adverbs.\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "An interesting text classification task could be Spam Detection to Identify whether an email or message is spam or not.\n",
        "This involves classifying incoming messages into \"spam\" or \"not spam\" categories.\n",
        "\n",
        "Below are the features that are useful for building a machine learning model:\n",
        "\n",
        "Bag of Words (BoW) Features:\n",
        "Word Frequency: Count the frequency of each word in the review. Positive sentiment may be associated with words like \"delicious,\" \"amazing,\"\n",
        "and \"friendly,\" while negative sentiment may be linked to words like \"disappointing,\" \"awful,\" and \"rude.\"\n",
        "\n",
        "N-grams Features:\n",
        "Bi-grams and Tri-grams: Consider word pairs (bi-grams) and word triplets (tri-grams) in addition to individual words. This can capture phrases\n",
        "like \"horrible service\" or \"good food\" which carry sentiment information.\n",
        "\n",
        "Temporal Features:\n",
        "Review Date and Time: Consider the timestamp of the review, as sentiment may vary over time. Reviews written shortly after a dining experience\n",
        "might be more emotionally charged than those written later.\n",
        "\n",
        "TF-IDF (Term Frequency-Inverse Document Frequency) Features:\n",
        "TF-IDF Scores: Calculate TF-IDF scores for each word in the review. This helps in giving more weight to words that are important to a\n",
        "specific review while downplaying common words.\n",
        "\n",
        "Punctuation and Capitalization Features:\n",
        "Punctuation Usage: Count the number of exclamation points, question marks, or ellipses in the review. Excessive use of exclamation points might\n",
        "indicate enthusiasm in positive reviews or frustration in negative reviews.\n",
        "\n",
        "Part-of-Speech (POS) Features:\n",
        "POS Tag Frequencies: Count the frequency of different parts of speech in the review, such as nouns, adjectives, verbs, and adverbs. Positive reviews\n",
        "might have a higher frequency of positive adjectives and verbs, while negative reviews might have more negative adjectives and adverbs.\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import string\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# Sample text data\n",
        "reviews = [\n",
        "    \"The food was delicious and the service was excellent!\",\n",
        "    \"I had a terrible experience. The food was awful and the staff was rude.\",\n",
        "    \"This place is just okay. Nothing special.\",\n",
        "]\n",
        "\n",
        "# Tokenize the text and remove stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    filtered_words = [word for word in words if word not in stop_words and word not in string.punctuation]\n",
        "    return filtered_words\n",
        "\n",
        "tokenized_reviews = [preprocess_text(review) for review in reviews]\n",
        "\n",
        "# Bag of Words (BoW) Features\n",
        "def bag_of_words(review, vocabulary):\n",
        "    bow_vector = [0] * len(vocabulary)\n",
        "    for word in review:\n",
        "        if word in vocabulary:\n",
        "            bow_vector[vocabulary.index(word)] += 1\n",
        "    return bow_vector\n",
        "\n",
        "# Create a vocabulary\n",
        "all_words = [word for review in tokenized_reviews for word in review]\n",
        "vocabulary = list(set(all_words))\n",
        "\n",
        "# Create BoW features\n",
        "bow_features = [bag_of_words(review, vocabulary) for review in tokenized_reviews]\n",
        "\n",
        "# TF-IDF Features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(reviews)\n",
        "\n",
        "# N-grams Features\n",
        "n = 2  # Change n to the desired n-gram size\n",
        "ngram_features = [list(ngrams(review, n)) for review in tokenized_reviews]\n",
        "\n",
        "# Part-of-Speech (POS) Features\n",
        "pos_features = [pos_tag(review) for review in tokenized_reviews]\n",
        "\n",
        "# Punctuation and Capitalization Features\n",
        "def punctuation_and_capitalization_features(review):\n",
        "    punctuation_count = sum(1 for char in review if char in string.punctuation)\n",
        "    capitalization_count = sum(1 for char in review if char.isupper())\n",
        "    return [punctuation_count, capitalization_count]\n",
        "\n",
        "punctuation_capitalization_features = [punctuation_and_capitalization_features(review) for review in reviews]\n",
        "\n",
        "# Temporal Features\n",
        "timestamp = [datetime.datetime.now() - datetime.timedelta(days=i) for i in range(len(reviews))]\n",
        "\n",
        "# Create a DataFrame to display the features\n",
        "feature_df = pd.DataFrame({\n",
        "    'Review': reviews,\n",
        "    'BoW Features': bow_features,\n",
        "    'TF-IDF Features': [tfidf.toarray().tolist() for tfidf in tfidf_features],\n",
        "    'N-grams Features': ngram_features,\n",
        "    'POS Features': pos_features,\n",
        "    'Punctuation & Capitalization Features': punctuation_capitalization_features,\n",
        "    'Timestamp': timestamp\n",
        "})\n",
        "\n",
        "print(feature_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koHSpKmsYtLD",
        "outputId": "38605c90-ad15-48bc-ea67-b9460b923bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  \\\n",
            "0  The food was delicious and the service was exc...   \n",
            "1  I had a terrible experience. The food was awfu...   \n",
            "2          This place is just okay. Nothing special.   \n",
            "\n",
            "                              BoW Features  \\\n",
            "0  [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]   \n",
            "1  [0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]   \n",
            "2  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1]   \n",
            "\n",
            "                                     TF-IDF Features  \\\n",
            "0  [[0.25660665102527236, 0.0, 0.3374069088879384...   \n",
            "1  [[0.22154791696626897, 0.2913088867162231, 0.0...   \n",
            "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3779644...   \n",
            "\n",
            "                                    N-grams Features  \\\n",
            "0  [(food, delicious), (delicious, service), (ser...   \n",
            "1  [(terrible, experience), (experience, food), (...   \n",
            "2  [(place, okay), (okay, nothing), (nothing, spe...   \n",
            "\n",
            "                                        POS Features  \\\n",
            "0  [(food, NN), (delicious, JJ), (service, NN), (...   \n",
            "1  [(terrible, JJ), (experience, NN), (food, NN),...   \n",
            "2  [(place, NN), (okay, NN), (nothing, NN), (spec...   \n",
            "\n",
            "  Punctuation & Capitalization Features                  Timestamp  \n",
            "0                                [1, 1] 2023-10-08 22:22:55.772652  \n",
            "1                                [2, 2] 2023-10-07 22:22:55.772664  \n",
            "2                                [2, 2] 2023-10-06 22:22:55.772668  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b74a31-b490-4212-8ff2-58b6b368ab4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: is, Chi-squared Score: 0.76\n",
            "Feature: just, Chi-squared Score: 0.76\n",
            "Feature: nothing, Chi-squared Score: 0.76\n",
            "Feature: okay, Chi-squared Score: 0.76\n",
            "Feature: place, Chi-squared Score: 0.76\n",
            "Feature: special, Chi-squared Score: 0.76\n",
            "Feature: this, Chi-squared Score: 0.76\n",
            "Feature: delicious, Chi-squared Score: 0.67\n",
            "Feature: excellent, Chi-squared Score: 0.67\n",
            "Feature: service, Chi-squared Score: 0.67\n",
            "Feature: awful, Chi-squared Score: 0.58\n",
            "Feature: experience, Chi-squared Score: 0.58\n",
            "Feature: had, Chi-squared Score: 0.58\n",
            "Feature: rude, Chi-squared Score: 0.58\n",
            "Feature: staff, Chi-squared Score: 0.58\n",
            "Feature: terrible, Chi-squared Score: 0.58\n",
            "Feature: the, Chi-squared Score: 0.49\n",
            "Feature: was, Chi-squared Score: 0.49\n",
            "Feature: and, Chi-squared Score: 0.24\n",
            "Feature: food, Chi-squared Score: 0.24\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "import numpy as np\n",
        "\n",
        "# Sample text data\n",
        "reviews = [\n",
        "    \"The food was delicious and the service was excellent!\",\n",
        "    \"I had a terrible experience. The food was awful and the staff was rude.\",\n",
        "    \"This place is just okay. Nothing special.\",\n",
        "]\n",
        "\n",
        "# Sample labels (for sentiment analysis, for example)\n",
        "labels = ['positive', 'negative', 'neutral']\n",
        "\n",
        "# Assume labels for each review (modify accordingly)\n",
        "review_labels = ['positive', 'negative', 'neutral']\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_map = {label: idx for idx, label in enumerate(labels)}\n",
        "numerical_labels = [label_map[label] for label in review_labels]\n",
        "\n",
        "# TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(reviews)\n",
        "\n",
        "# Chi-squared test for feature selection\n",
        "chi2_scores, _ = chi2(tfidf_features, numerical_labels)\n",
        "\n",
        "# Create a dictionary to associate feature names with chi-squared scores\n",
        "feature_scores = {feature_name: score for feature_name, score in zip(tfidf_vectorizer.get_feature_names_out(), chi2_scores)}\n",
        "\n",
        "# Sort features by their chi-squared scores in descending order\n",
        "sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the top N features and their scores\n",
        "top_n = 20  # Change to the desired number of top features\n",
        "for feature, score in sorted_features[:top_n]:\n",
        "    print(f\"Feature: {feature}, Chi-squared Score: {score:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78dcbbab-0a22-4f68-f905-87edcf77a7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Text Data:\n",
            "Rank 1: Similarity 0.9337 - Text: I had a terrible experience. The food was awful and the staff was rude.\n",
            "Rank 2: Similarity 0.9222 - Text: This place is just okay. Nothing special.\n",
            "Rank 3: Similarity 0.9175 - Text: The food was delicious and the service was excellent!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Sample text data\n",
        "reviews = [\n",
        "    \"The food was delicious and the service was excellent!\",\n",
        "    \"I had a terrible experience. The food was awful and the staff was rude.\",\n",
        "    \"This place is just okay. Nothing special.\",\n",
        "]\n",
        "\n",
        "# Query text\n",
        "query = \"I want to find a great restaurant with delicious food and excellent service.\"\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the query\n",
        "query_tokens = tokenizer.encode(query, add_special_tokens=True, max_length=128, truncation=True, padding='max_length', return_tensors='pt')\n",
        "\n",
        "# Encode the query using the BERT model\n",
        "with torch.no_grad():\n",
        "    query_embeddings = model(query_tokens)[0][0]  # [CLS] token embedding for the query\n",
        "\n",
        "# Calculate cosine similarity between query and text data\n",
        "similarities = []\n",
        "for review in reviews:\n",
        "    review_tokens = tokenizer.encode(review, add_special_tokens=True, max_length=128, truncation=True, padding='max_length', return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        review_embedding = model(review_tokens)[0][0]  # [CLS] token embedding for each review\n",
        "    similarity = cosine_similarity(query_embeddings.reshape(1, -1), review_embedding.reshape(1, -1))\n",
        "    similarities.append(similarity[0][0])\n",
        "\n",
        "# Rank the text data by similarity in descending order\n",
        "ranking = np.argsort(similarities)[::-1]\n",
        "\n",
        "# Print the ranked text data\n",
        "print(\"Ranked Text Data:\")\n",
        "for i, idx in enumerate(ranking):\n",
        "    print(f\"Rank {i + 1}: Similarity {similarities[idx]:.4f} - Text: {reviews[idx]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q9Y1jy05bA8u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}